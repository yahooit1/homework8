{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMF31hmSpj8iSEPdp067wcr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yahooit1/homework8/blob/main/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsYpusOMnSqK"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from keras.layers import Conv2D, Dense, BatchNormalization, Activation, Dropout,MaxPooling2D,Flatten\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.optimizers import Adam,RMSprop,SGD\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "import datetime\n",
        "from keras import regularizers\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils.vis_utils import plot_model"
      ],
      "metadata": {
        "id": "WeFDyuUnnZGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_array = cv2.imread(\"/content/drive/MyDrive/archive (1)/train/angry/Training_34758750.jpg\") # no korean in path"
      ],
      "metadata": {
        "id": "QjQ0p7iAnazq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img_array)"
      ],
      "metadata": {
        "id": "ektvfoUJ38EY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir=\"/content/drive/MyDrive/archive (1)/train/\"\n",
        "test_dir='/content/drive/MyDrive/archive (1)/test/'\n",
        "\n",
        "row, col = 48, 48\n",
        "classes = 7\n",
        "\n",
        "def count_exp(path, set_):\n",
        "    dict_ = {}\n",
        "    for expression in os.listdir(path):\n",
        "        dir_ = path + expression\n",
        "        dict_[expression] = len(os.listdir(dir_))\n",
        "    df = pd.DataFrame(dict_, index=[set_])\n",
        "    return df\n",
        "train_count = count_exp(train_dir, 'train')\n",
        "test_count = count_exp(test_dir, 'test')\n",
        "print(train_count)\n",
        "print(test_count)"
      ],
      "metadata": {
        "id": "GrmnAM2TneZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14,22))\n",
        "i = 1\n",
        "for expression in os.listdir(train_dir):\n",
        "    img = load_img((train_dir + expression +'/'+ os.listdir(train_dir + expression)[5]))\n",
        "    plt.subplot(1,7,i)\n",
        "    plt.imshow(img)\n",
        "    plt.title(expression)\n",
        "    plt.axis('off')\n",
        "    i += 1\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KiDl__vXne_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   horizontal_flip=True,\n",
        "                                   validation_split=0.2)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory(train_dir,\n",
        "                                                batch_size=64,\n",
        "                                                target_size=(48,48),\n",
        "                                                shuffle=True,\n",
        "                                                color_mode='grayscale',\n",
        "                                                class_mode='categorical',\n",
        "                                                subset='training')\n",
        "\n",
        "\n",
        "validation_set = train_datagen.flow_from_directory(train_dir,\n",
        "                                                batch_size=64,\n",
        "                                                target_size=(48,48),\n",
        "                                                shuffle=True,\n",
        "                                                color_mode='grayscale',\n",
        "                                                class_mode='categorical',\n",
        "                                                subset='validation')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   horizontal_flip=True)\n",
        "test_set = test_datagen.flow_from_directory(test_dir,\n",
        "                                                batch_size=64,\n",
        "                                                target_size=(48,48),\n",
        "                                                shuffle=True,\n",
        "                                                color_mode='grayscale',\n",
        "                                                class_mode='categorical')"
      ],
      "metadata": {
        "id": "1Cn0RVULngpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# labels \n",
        "training_set.class_indices"
      ],
      "metadata": {
        "id": "JwyurHHMniLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_decay = 1e-4\n",
        "\n",
        "num_classes = 7\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(Conv2D(64, (4,4), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=(48,48,1)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (4,4), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        " \n",
        "model.add(Conv2D(128, (4,4), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        " \n",
        "model.add(Conv2D(128, (4,4), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (4,4), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation=\"linear\"))\n",
        "model.add(Activation('elu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.0003), metrics=['accuracy'])\n",
        " \n",
        "model.summary()"
      ],
      "metadata": {
        "id": "oo5wdX6Tnk1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "MNuuwmeVnlTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpointer = [ModelCheckpoint(\n",
        "                    filepath='model.weights.best.hdf5',\n",
        "                    monitor=\"val_accuracy\",\n",
        "                    verbose=1,\n",
        "                    save_best_only=True,\n",
        "                    mode=\"max\")]"
      ],
      "metadata": {
        "id": "Qy0_Ufi4nm6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = training_set.n // training_set.batch_size\n",
        "validation_steps = validation_set.n // validation_set.batch_size\n",
        "\n",
        "history = model.fit(x=training_set,\n",
        "                 validation_data=validation_set,\n",
        "                 epochs=30,\n",
        "                 callbacks=[checkpointer],\n",
        "                 steps_per_epoch=steps_per_epoch,\n",
        "                 validation_steps=validation_steps)"
      ],
      "metadata": {
        "id": "gMmHXcMDnpk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "plt.rcParams['figure.figsize'] = [10, 5]\n",
        "plt.style.use(['default'])\n",
        "# Create count of the number of epochs\n",
        "epoch_count = range(1, len(training_loss) + 1)\n",
        "\n",
        "# Visualize loss history\n",
        "plt.plot(epoch_count, training_loss, 'r--')\n",
        "plt.plot(epoch_count, val_loss, 'b-')\n",
        "plt.legend(['Training Loss', 'Val Loss'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J6bHESYinqN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "# Create count of the number of epochs\n",
        "epoch_count = range(1, len(training_accuracy) + 1)\n",
        "\n",
        "# Visualize loss history\n",
        "\n",
        "plt.plot(epoch_count, training_accuracy, 'r--')\n",
        "plt.plot(epoch_count, val_accuracy, 'b-')\n",
        "plt.legend(['Training Accuracy', 'Val Accuracy'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(top = 1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ew51nYIvnsC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the model\n",
        "model.save(\"fer_model.h5\")"
      ],
      "metadata": {
        "id": "yUiYNfDmntuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Test accuracy = {model.evaluate(test_set ,batch_size=test_set.batch_size,steps=test_set.n // test_set.batch_size)[1]*100}%\")"
      ],
      "metadata": {
        "id": "tnAXF9DjnwZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion Matrix / Training , Validation , Test"
      ],
      "metadata": {
        "id": "fvGpQoF9Bf1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(training_set)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "class_labels = test_set.class_indices\n",
        "class_labels = {v:k for k,v in class_labels.items()}\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "cm_train = confusion_matrix(training_set.classes, y_pred)\n",
        "print('Confusion Matrix')\n",
        "print(cm_train)\n",
        "print('Classification Report')\n",
        "target_names = list(class_labels.values())\n",
        "print(classification_report(training_set.classes, y_pred, target_names=target_names))\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(cm_train, interpolation='nearest')\n",
        "plt.colorbar()\n",
        "tick_mark = np.arange(len(target_names))\n",
        "_ = plt.xticks(tick_mark, target_names, rotation=90)\n",
        "_ = plt.yticks(tick_mark, target_names)"
      ],
      "metadata": {
        "id": "6j6xvoOfBDQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(validation_set)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "cm_val = confusion_matrix(validation_set.classes, y_pred)\n",
        "print('Confusion Matrix')\n",
        "print(cm_val)\n",
        "print('Classification Report')\n",
        "target_names = list(class_labels.values())\n",
        "print(classification_report(validation_set.classes, y_pred, target_names=target_names))\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(cm_train, interpolation='nearest')\n",
        "plt.colorbar()\n",
        "tick_mark = np.arange(len(target_names))\n",
        "_ = plt.xticks(tick_mark, target_names, rotation=90)\n",
        "_ = plt.yticks(tick_mark, target_names)"
      ],
      "metadata": {
        "id": "cwErcKBPBJVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(test_set)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "cm_test = confusion_matrix(test_set.classes, y_pred)\n",
        "print('Confusion Matrix')\n",
        "print(cm_test)\n",
        "print('Classification Report')\n",
        "target_names = list(class_labels.values())\n",
        "print(classification_report(test_set.classes, y_pred, target_names=target_names))\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(cm_test, interpolation='nearest')\n",
        "plt.colorbar()\n",
        "tick_mark = np.arange(len(target_names))\n",
        "_ = plt.xticks(tick_mark, target_names, rotation=90)\n",
        "_ = plt.yticks(tick_mark, target_names)"
      ],
      "metadata": {
        "id": "2dbJujruBMvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test,y_test = next(test_set)\n",
        "predict = model.predict(x_test)"
      ],
      "metadata": {
        "id": "xcPg8WhuBTsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(20, 8))\n",
        "for i, index in enumerate(np.random.choice(x_test.shape[0], size=24, replace=False)):\n",
        "    ax = figure.add_subplot(4, 6, i + 1, xticks=[], yticks=[])\n",
        "    ax.imshow(np.squeeze(x_test[index]))\n",
        "    predict_index = class_labels[(np.argmax(predict[index]))]\n",
        "    true_index = class_labels[(np.argmax(y_test[index]))]\n",
        "    \n",
        "    ax.set_title(\"{} ({})\".format((predict_index), \n",
        "                                  (true_index)),\n",
        "                                  color=(\"green\" if predict_index == true_index else \"red\"))"
      ],
      "metadata": {
        "id": "Ya84sE2RBWTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from matplotlib import pyplot as plt # this lets you draw inline pictures in the notebooks\n",
        "import pylab # this allows you to control figure size "
      ],
      "metadata": {
        "id": "-ROEavUvnxRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_classifier=cv2.CascadeClassifier('/content/drive/MyDrive/haarcascade_frontalface_default.xml')\n",
        "classifier = load_model('/fer_model.h5')"
      ],
      "metadata": {
        "id": "QDWwi3NOob-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels=training_set.class_indices\n",
        "img_array = cv2.imread(\"/content/drive/MyDrive/archive (1)/train/angry/Training_34758750.jpg\")\n",
        "gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)\n",
        "face_cascade = cv2.CascadeClassifier('/content/drive/MyDrive/haarcascade_frontalface_default.xml')\n",
        "faces = face_cascade.detectMultiScale(gray, 1.3, 5)"
      ],
      "metadata": {
        "id": "UaKcKezMohAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (x,y,w,h) in faces:\n",
        "    cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "    roi_gray=gray[y:y+h,x:x+w]\n",
        "    roi_gray=cv2.resize(roi_gray,(48,48),interpolation=cv2.INTER_AREA)"
      ],
      "metadata": {
        "id": "W2AP-tFCotHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if np.sum([roi_gray])!=0:\n",
        "   roi=roi_gray.astype('float')/255.0\n",
        "   roi=img_to_array(roi)\n",
        "   roi=np.expand_dims(roi,axis=0)\n",
        "   preds=classifier.predict(roi)[0]\n",
        "   label=class_labels[preds.argmax()]\n",
        "   label_position=(x,y)\n",
        "   cv2.putText(frame,label,label_position,cv2.FONT_HERSHEY_SIMPLEX,2,(0,255,0),3)\n",
        "else:\n",
        "   cv2.putText(frame,'No Face Found',(20,20),cv2.FONT_HERSHEY_SIMPLEX,2,(0,255,0),3)\n",
        "cv2.imshow('Emotion Detector',frame)\n",
        "if cv2.waitKey(1) & 0xFF == ord('q'): #q를 입력하면 이미지 내려감. \n",
        "   break"
      ],
      "metadata": {
        "id": "UcTMkDSFqj3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_array.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "Bc9BQ16tqtUl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}